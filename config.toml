[openai]
## Configuration section for interacting with the OpenAI API.

# Base URL for making API requests to OpenAI.
base_url = "https://api.openai.com/v1"

# API key for authentication when using the OpenAI API.
api_key = "your_api_key_here"

# Model name used for generating text. Options include 'gpt-3.5-turbo', 'gpt-4', etc.
model_name = "gpt-3.5-turbo"


[server]
## Configuration section for the server.

# Host address where the server will listen for incoming requests.
host = "0.0.0.0"

# Port number on which the server will listen for incoming requests.
port = 5000


[database]
## Configuration section for the database.
## The database is used to cache translated text.

# Name of the database file where translated texts are stored.
db_file = "translated_texts.db"

# If true, save each translation to the database for future requests.
cache_translation = true

# If true, use a cached translation from the database if it exists.
use_cached_translation = true

# If true, use the latest records to initialize the prompt.
use_latest_records = true

# Number of latest records to use for initializing the prompt.
init_latest_records = 30


[history]
## Context-Aware Translation configuration.
## This configuration helps maintain context for more natural translations.

# If true, use context-aware translation.
use_history = true

# Maximum number of history items to save in the prompt.
# If -1, all history is saved in the prompt.
max_history = 30

# If true, use the latest history for the prompt. This may slow response times but improve translation quality.
use_latest_history = true


[logging]
## Configuration section for logging.

## Log level to use for logging. Options include 'DEBUG', 'INFO', 'WARNING', 'ERROR', 'CRITICAL'.
log_level = "INFO"

# File path where logs will be written.
log_file = "app.log"


[model]
## Model parameters configuration.
## This section contains parameters for the model used for generating text.

# Temperature controls the randomness of the output. Lower values make the output more deterministic.
# On translation tasks, a value of 0 is highly recommended.
temperature = 0.0

# Maximum number of tokens to generate in the output.
max_tokens = 2048

# Penalty applied to repeated words or phrases in the generated text.
# A value of 0.0 means no penalty, allowing repeated words without cost.
frequency_penalty = 0.0

# Penalty applied to new lines in the generated text.
# A value of 0.0 means no penalty, allowing repeated new lines without cost.
presence_penalty = 0.0